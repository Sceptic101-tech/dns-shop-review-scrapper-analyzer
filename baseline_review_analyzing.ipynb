{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0213355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parser import DNS_Shop_Parser\n",
    "from keybert import KeyBERT\n",
    "from pymystem3 import Mystem\n",
    "from wordcloud import WordCloud\n",
    "import  multiprocessing as mp\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f6b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO многпоточная лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8be5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt_tab')\n",
    "# stopwords = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc40eb",
   "metadata": {},
   "source": [
    "На вход приходит список словарей. Каждый словарь может содержать ключи 'Достоинства', 'Недостатки', 'Комментарий', 'Фото', а также ключи вида \"Дополнение от 27 мая 2025 года\", от которых необходимо избавиться.\\\n",
    "Наблюдение: если в отзыве есть \"Дополнение...\", то есть как минимум 'Достоинства' или 'Недостатки' или 'Комментарий'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4560b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list_of_reviews(reviews):\n",
    "    dict_of_none = {'Достоинства' : None, 'Недостатки' : None, 'Комментарий' : None, 'Фото' : None}\n",
    "    texts = []\n",
    "    for review in reviews:\n",
    "        if review != dict_of_none:\n",
    "            texts.append('') # if all the values in review is None, but if it has some key, that is not in dict_of_none -> memory leak. need to fix that\n",
    "            for key, value in review.items():\n",
    "                if (value is not None) and (key in dict_of_none.keys()):\n",
    "                    texts[-1] += ' ' + value + ' '\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d987e",
   "metadata": {},
   "source": [
    "Препроцессинг текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d55ce341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_list_of_texts(list_of_texts) -> list:\n",
    "    preprocessed_list_of_texts = []\n",
    "    for text in list_of_texts:\n",
    "        preprocessed_list_of_texts.append(text.lower())\n",
    "        # texts[i] = re.sub(r'[^\\w\\s]', '', texts[i].lower())\n",
    "    return preprocessed_list_of_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dfab54",
   "metadata": {},
   "source": [
    "Возможность пердварительной лемматизации отзывов, перед извлечением ключевых N-грамм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7dbd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmatized_text(list_of_texts, mystem: Mystem) -> list:\n",
    "    lemmatized_texts = []\n",
    "    for text in list_of_texts:\n",
    "        lemmatized_texts.append(''.join(mystem.lemmatize(text)))\n",
    "    return lemmatized_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc7826b",
   "metadata": {},
   "source": [
    "Извлечение ключевых N-грамм из каждого отзыва"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee9cb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keyphrases(corpus_list, model : KeyBERT, top_n=2, keyphrase_ngram_range=(1,2)) -> list:\n",
    "    raw_keywords_list = []\n",
    "    for corpus in corpus_list:\n",
    "        raw_keywords_list.append(model.extract_keywords(docs=corpus, keyphrase_ngram_range=keyphrase_ngram_range,\n",
    "                                                    stop_words=None, top_n=top_n, diversity=0.7))\n",
    "    return raw_keywords_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d86a33",
   "metadata": {},
   "source": [
    "Функция необходима для преобразования списка, получаемого после **extract_keyphrases()**, в словарь, пригодный для исопльзования в библиотеке wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67c4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_keywords(keywords_lists, threshold=0.5) -> dict:\n",
    "    '''destined for wordcloud.\n",
    "       Returns dictionary: key = keyword, value = [0,1]'''\n",
    "    propper_keywords = {}\n",
    "    for keyword_list in keywords_lists:\n",
    "        for keyword in keyword_list:\n",
    "            if keyword[1] >= threshold:\n",
    "                propper_keywords[keyword[0]] = keyword[1]\n",
    "    return propper_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = DNS_Shop_Parser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69588f5",
   "metadata": {},
   "source": [
    "Извлечение отзывов из текстового файла на время тестов, воизбежание бана в ДНС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59bcdb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "with open('raw_html_big.txt', 'r', encoding='utf-8') as file:\n",
    "    reviews = parser.extract_reviews(file.read()) # propper form: list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74bfbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлечение отзывов задуманным способом\n",
    "# parser.open_DNS_site() # execute once\n",
    "# reviews = parser.get_product_reviews() # propper form: list of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ef329",
   "metadata": {},
   "source": [
    "Препроцессинг корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "218c1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_list = preprocess_list_of_texts(convert_to_list_of_reviews(reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c19985c",
   "metadata": {},
   "source": [
    "Токенизация и очистка от стоп-слов (не используется, поскольку отсутствие стоп-слов портит семантику корпуса => несвязанные ключевые N-граммы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f63164d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_tokens = []\n",
    "# for text in raw_list_corpus:\n",
    "#     list_tokens.append(nltk.tokenize.word_tokenize(text, language='russian'))\n",
    "\n",
    "# cleaned_corpus_list = []\n",
    "# allowed_stopwords = ['не', 'ни']\n",
    "# for review in list_tokens:\n",
    "#     cleaned_corpus = []\n",
    "#     for token in review:\n",
    "#         if (token not in stopwords) or (token in allowed_stopwords):\n",
    "#             cleaned_corpus.append(token)\n",
    "#     cleaned_corpus_list.append(' '.join(cleaned_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "382e26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyBERT('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dac313",
   "metadata": {},
   "source": [
    "Облако слов без лемматизации крпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eff9808",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_keywords_list = extract_keyphrases(preprocessed_list, model, 2, (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfca21a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_dict = get_dict_keywords(raw_keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06d58094",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width = 1000, \n",
    "                      height = 1000, \n",
    "                      background_color='black', \n",
    "                      margin=20, \n",
    "                      colormap='Pastel1', \n",
    "                      collocations=True, \n",
    "                      random_state=42)\n",
    "\n",
    "wordcloud.generate_from_frequencies(keywords_dict)\n",
    "image = wordcloud.to_image()\n",
    "image.show()\n",
    "image.save('no_lemmatized_before_keyphrase_extraction.PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090085d7",
   "metadata": {},
   "source": [
    "Облако слов с лемматизацией корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c56d47fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87fc6333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# При таком подходе лемматизация занимает чуть более 7 минут\n",
    "# lemmatized_list = get_lemmatized_text(preprocessed_list, mystem)    # Необходима оптимизация + многопоточность. \n",
    "                                                                    # Другой вариант - сконкатенировать список в один большой текст и добавить разделитель. Далее по разделителю преобразовать в список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b3c3ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = '!@#$%^&*()' # Костыльный разделитель.\n",
    "lemmatized_text = ''.join(mystem.lemmatize(splitter.join(preprocessed_list)))\n",
    "lemmatized_list = lemmatized_text.split(splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bc8ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_keywords_list = extract_keyphrases(lemmatized_list, model, 2, (1,2))\n",
    "keywords_dict = get_dict_keywords(raw_keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "193e50f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width = 1000, \n",
    "                      height = 1000, \n",
    "                      background_color='black', \n",
    "                      margin=20, \n",
    "                      colormap='Pastel1', \n",
    "                      collocations=True, \n",
    "                      random_state=42)\n",
    "\n",
    "wordcloud.generate_from_frequencies(keywords_dict)\n",
    "image = wordcloud.to_image()\n",
    "image.show()\n",
    "image.save('lemmatized_before_keyphrase_extraction.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44db9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
